---
layout: default
title: Resource Hub for GenAI in the Social Sector
date: 02/29/2024
author: Rachel Wells with help from John Harnisher, Matt Harris, Lindsey Washburn, Kathleen Yaworsky 
audience: Social Impact Professionals
category: social-impact
subcategory: genai
---

Looking for more? This field is constantly changing, but here are some resources that DataKind finds particularly useful for social impact organizations considering using Generative AI. 


DataKind's perspective on GenAI use for the social sector:


* [Webinar series: DataKind introduces GenAI](https://www.youtube.com/watch?v=OgKQZG1uTV0&t=5s) in February 2023 and then shares about [A Year of GenAI Learning](https://youtu.be/Rk6jiKfJxsQ?si=dTsjz30GkBNcx4QZ) as of February 2024, and finally on [GenAI in Action at Nonprofits](https://www.youtube.com/watch?v=TBhA-78XKjw&t=240s) April 2024
* [Report on GenAI for humanitarians](https://href.li/?https://app.box.com/s/ybwizbcdxknn2cw8td08hcnl5hc1cl2e) (DataKind’s Head of Data Science contributed to this)
* [WEF Data Equity: Foundational Concepts for Generative AI](https://www.weforum.org/publications/data-equity-foundational-concepts-for-generative-ai/) (DataKind’s CEO contributed to this)
* [AI for humanitarians](https://www.thenewhumanitarian.org/feature/2023/09/05/ai-humanitarians-conversation-hype-hope-future?utm_source=The+New+Humanitarian&utm_campaign=5cfe0f192f-EMAIL_CAMPAIGN_2023_09_8&utm_medium=email&utm_term=0_d842d98289-5cfe0f192f-75815290) (DataKind’s CEO contributed to this)
* Find all technical blogs of DataKind’s GenAI project work [on Medium here](https://medium.com/@astrobagel)
* Project work example: a summary of our [humanitarian data insights project report](https://drive.google.com/file/d/1l2yE12msxbKxSnPGkyI8vGYq8b5N2pNo/view?usp=drive_link) on GenAI research
* [DataKind’s internal policy for Generative AI](https://drive.google.com/file/d/1phGrX1tC_OhzD_FZPUrrrOwY1zIdb2Re/view)


Example social sector solutions:


* [ICTworks answer bot](https://www.ictworks.org/introducing-ictworks-answer-bot/)
* An AI tool with curated content for nonprofits: <https://www.nonprofitama.ai> (and [an interview with the founder](https://www.linkedin.com/video/live/urn:li:ugcPost:7137821040671416320/))
* [Open\-access LLM fine\-tuned for Swahili](https://www.linkedin.com/posts/activity-7122925177750904832-aKIz/?utm_source=share&utm_medium=member_desktop)
* [2 GenAI chatbox solution examples for nonprofits](https://www.ictworks.org/genai-chatbots-health-education-impact/)
* [Chatbot resources from the Engine Room](https://www.ictworks.org/using-chatbots-humanitarian-programs/)
* [Use cases in Indonesia](https://www.ictworks.org/indonesians-generative-ai-social-impact/)
* [GenAI transforms crisis management](https://www.nextgov.com/ideas/2023/10/generative-ai-set-transform-crisis-management/391264/)
* [AI for paid parental leave](https://time.com/6342280/ai-paid-leave-social-good/)
* [Using NLP to detect mental health crises](https://hai.stanford.edu/news/using-nlp-detect-mental-health-crises?utm_source=Stanford+HAI&utm_campaign=4d2d53e3e1-EMAIL_CAMPAIGN_2024_01_10_11_32_COPY_01&utm_medium=email&utm_term=0_aaf04f4a4b-f0e42e97e6-%5BLIST_EMAIL_ID%5D&mc_cid=4d2d53e3e1&mc_eid=3e9160b2df)
* [Examples from Fast Forward labs on how AI is being used for humanity](https://www.ffwd.org/ai-for-humanity/) (links to various media sources)
* [Development \& Humanitarian GenAI tools directory](https://docs.google.com/spreadsheets/d/1xihdkTEQ1ZIbvIvgxBa_ogZqWdV6CCnfHhaf7fW5ikM/edit?gid=1730585908#gid=1730585908)
* [Social impact chatbot database](https://tangibleai.com/social-impact-chatbot-database/)


Defining terms:


* [Equitable \& accountable AI from AJL](https://www.ajl.org/learn-more)
* [Equitable AI from the Aspen Institute](https://www.aspeninstitute.org/wp-content/uploads/2023/01/Equitable-AI-Aspen-Institute.pdf)


Understanding the challenges:


* [LLM challenges and applications](https://arxiv.org/pdf/2307.10169.pdf)
* [Evaluation of trustworthiness of LLMs from HAI](https://stanford.us18.list-manage.com/track/click?u=e4cec5598a9700340ecc55eef&id=d3c7923a2b&e=3e9160b2df)
* [On the opportunities \& risks of transformer models](https://arxiv.org/abs/2108.07258)
* [Biden’s executive order for AI safety](https://www.whitehouse.gov/briefing-room/statements-releases/2023/10/30/fact-sheet-president-biden-issues-executive-order-on-safe-secure-and-trustworthy-artificial-intelligence/)
* [LLM security flaw is no easy fix \- WIRED](https://www.wired.com/story/generative-ai-prompt-injection-hacking/?utm_source=substack&utm_medium=email)
* \[Academic paper] [On the Dangers of Stochastic Parrots](https://dl.acm.org/doi/abs/10.1145/3442188.3445922) [\| Proceedings of the 2021 ACM](https://dl.acm.org/doi/abs/10.1145/3442188.3445922) [Conference on Fairness, Accountability, and Transparency](https://dl.acm.org/doi/abs/10.1145/3442188.3445922)
* \[Non\-technical blog post] [Risks and ethical considerations of generative AI](https://www2.deloitte.com/uk/en/blog/financial-services/2023/risks-and-ethical-considerations-of-generative-ai.html)
* \[Video] [AI Dilemma](https://www.youtube.com/watch?v=xoVJKj8lcNQ) (and [counterpoint to AI Dilemma](https://alexasteinbruck.medium.com/lets-hope-the-ai-dilemma-never-gets-turned-into-a-netflix-series-6c4de6a5d282))
* [Is meaningful participation and accountability in AI possible?](https://merltech.org/is-meaningful-participation-and-accountability-in-ai-possible/)
* [Why AI needs a nutrition label](https://www.ted.com/talks/kasia_chmielinski_why_ai_needs_a_nutrition_label?subtitle=en&trigger=30s)


Understanding the opportunities:


* \[Video] [Generative AI in a Nutshell](https://www.youtube.com/watch?v=2IK3DFHRFfw)
* \[Video] [Andrew Ng: Opportunities in AI \- 2023](https://www.youtube.com/watch?v=5p248yoa3oE)
* \[Technical blog post] [Explainable AI: Visualizing Attention in Transformers](https://generativeai.pub/explainable-ai-visualizing-attention-in-transformers-4eb931a2c0f8)
* [Mckinsey's research on Generative AI and the Future of Work in America](https://www.mckinsey.com/mgi/our-research/generative-ai-and-the-future-of-work-in-america)
* [Funders for GenAI for social impact](https://www.forbes.com/sites/fastforward/2024/01/17/the-visionary-leaders-backing-the-builders-of-ai-for-humanity/?sh=60a2e13173eb)
* [Deploying GenAI in the Real World](https://medium.com/cooper-smith/deploying-genai-in-the-real-world-3df5346e3994) (global health)


Guidelines on responsible AI for nonprofits:


* [Responsible AI framework selection matrix](https://montrealethics.ai/a-matrix-for-selecting-responsible-ai-frameworks/?utm_source=substack&utm_medium=email)
* [The Equitable AI Playbook](https://www.peatworks.org/ai-disability-inclusion-toolkit/the-equitable-ai-playbook/)
* [Simple steps for responsible AI adoption for nonprofits](https://ssir.org/articles/entry/8_steps_nonprofits_can_take_to_adopt_ai_responsibly?utm_source=data.org&utm_campaign=f915d254ce-EMAIL_CAMPAIGN_2023_09_15_07_48&utm_medium=email&utm_term=0_-f915d254ce-%5BLIST_EMAIL_ID%5D)
* [DRAFT responsible GenAI framework from Dataiku](https://content.dataiku.com/email-responsible-genai?utm_campaign=GLO+CONTENT+Generative+AI+June+2023&utm_medium=email&_hsmi=278693253&_hsenc=p2ANqtz--2PrR9iSlKA1zhxcQ4Kl8WnVqUw9rjsjjGENKGR6FZkSJI1SIvrLATmltssuBNstq6PzuXDuwDo623wpHBwPKQbAVmZw&utm_content=277191530&utm_source=hs_email)
* \[Non\-technical blog post] [Embedding controls and risk mitigations throughout the generative AI development lifecycle](https://www2.deloitte.com/uk/en/pages/deloitte-analytics/articles/embedding-controls-and-risk-mitigations-throughout-the-generative-ai-development-lifecycle.html)
* [7 Ethical Considerations When Implementing AI at Nonprofits](https://www.bwf.com/7-ethical-considerations-when-implementing-ai-at-nonprofits/)
* [Acceptable use of AI tools in nonprofit workforce](https://communityit.com/template-acceptable-use-of-ai-tools-in-the-nonprofit-workplace/)
* [10 ways to help your organization manage the pain of AI adoption](https://merltech.org/10-ways-to-help-your-organization-manage-the-pain-of-ai-adoption/)
* [Advanced AI evaluation at AISI](https://www.aisi.gov.uk/work/advanced-ai-evaluations-may-update)
* [AI framework for an equitable world from NTEN](https://www.nten.org/publications/artificial-intelligence-framework-for-an-equitable-world)


Technical Papers and Articles on responsible AI:


* [Fair ML book](https://fairmlbook.org/)
* [Paper that takes a more human approach to creating fair algorithms](https://arxiv.org/pdf/2201.10408.pdf)
* [An overview of all the different points where bias could enter the machine learning life cycle](https://arxiv.org/pdf/1901.10002.pdf)
* [How to make transparent the effects of protected attributes on machine learning algorithms](https://arxiv.org/pdf/2302.03874.pdf)
* [Red teaming with LLMs](https://www.deepmind.com/publications/red-teaming-language-models-with-language-models)
* [Testing framework utilizing the idea of unit tests for LLMs](https://aclanthology.org/2020.acl-main.442.pdf)
* [Privacy](https://arxiv.org/abs/1802.08232)
* [How we tend to fall into traps because we don't think of systems sociotechnically](https://dl.acm.org/doi/10.1145/3287560.3287598)


Tools:


* [Fun blog on GenAI tools for USAID](https://www.ictworks.org/chatgpt-does-not-understand-usaid/)
* [Foundation model transparency index from Stanford](https://crfm.stanford.edu/fmti/)
* Getting started with creating custom versions of ChatGPT: [GPTs](https://openai.com/blog/introducing-gpts) and [GPT store](https://gptstore.ai/)
* [Fairlearn: Responsible AI tool](https://fairlearn.org)
* [IBM’s responsible AI tool for traditional ML](https://aif360.res.ibm.com/)
* [Ethics checklist for machine learning development](https://deon.drivendata.org/)


Governance:


* [AI Localism for Effective Governance](https://www.slideshare.net/StefaanVerhulst/ai-localism-toward-effective-and-legitimate-governance-of-artificial-intelligence)
* \[Academic paper] [Do Foundation Model Providers Comply with the Draft EU AI Act?](https://crfm.stanford.edu/2023/06/15/eu-ai-act.html)


Language:


* [Linguistic Justice and GenAI](https://lsa.umich.edu/sweetland/instructors/guides-to-teaching-writing/linguistic-justice-genai.html)
* [How language constrain GenAI development](https://www.brookings.edu/articles/how-language-gaps-constrain-generative-ai-development/)


Social program evaluation:


* [Prompt Engineering for MERL: tips and cautions](https://merltech.org/prompt-engineering-for-merl-tips-and-cautions/)
* [AI assistant for survey researchers](https://www.linkedin.com/pulse/under-the-hood-ai-beyond-chatbots-christopher-robert-dquue/)
* [How Language Models help evaluators tell better stories](https://merltech.org/how-can-evaluators-use-nlp-4-demos-and-a-discussion-at-the-aea-conference/)
* [What’s next for emerging AI in evaluation?](https://merltech.org/emerging-ai-for-evaluation/)
* AEA’s New Directions for Evaluation Journal’s special edition on [Evaluation and Artificial Intelligence](https://onlinelibrary.wiley.com/toc/1534875x/2023/2023/178-179)
* [3 blog series from the World Bank on evaluating evaluation use cases](https://ieg.worldbankgroup.org/blog/setting-experiments-test-gpt-evaluation)


Proposal writing:


* [Winning Funding Proposals Written by Generative AI: Should That Matter to You?](https://www.ictworks.org/proposals-written-generative-ai/)


Education sector:


* [The AI Divide Equitable Applications of AI in Higher Education to Advance the Completion Agenda](https://eric.ed.gov/?q=machines&ff1=pubOpinion+Papers&ff2=dtySince_2004&id=ED633824)
* [Attainment with AI Making a Real Difference in College Completion with Artificial Intelligence](https://eric.ed.gov/?q=use+AND+technology+AND+education&ff1=audPolicymakers&id=ED633822)
* [Why Teacher Intelligence Will Always Matter More Than Artificial Intelligence](https://www.erblearn.org/blog/ai-wont-replace-teacher-intelligence/)


Going deeper on AI:


* [\[TED talk] The magical AI assistants of the future and the engineering behind them](https://www.ted.com/talks/harrison_chase_the_magical_ai_assistants_of_the_future_and_the_engineering_behind_them)
* [State of AI report in slide deck form](https://docs.google.com/presentation/d/156WpBF_rGvf4Ecg19oM1fyR51g4FAmHV3Zs0WLukrLQ/edit#slide=id.g24daeb7f4f0_0_3373)
* [\[Textbook] Generative Deep Learning, 2nd Edition \[Book]](https://www.oreilly.com/library/view/generative-deep-learning/9781098134174/)
* [Blog on mitigating hallucinations](https://amatriain.net/blog/hallucinations)
* [Paper on extracting structured data from unstructured documents using LLMs](https://arxiv.org/abs/2309.08963) (which DataKind has done with PDF to data dictionary for IMF) with [new benchmark](https://github.com/gersteinlab/Struc-Bench) and Chain of Thought (CoT) technique to improve results
* [Microsoft open source framework](https://github.com/microsoft/autogen) "that enables development of LLM applications using multiple agents that can converse with each other to solve tasks" ([examples here](https://microsoft.github.io/autogen/docs/Examples))
* [Learning From Mistakes Makes LLM Better Reasoner](https://arxiv.org/abs/2310.20689)
* [Levels of AGI by Google DeepMind](https://arxiv.org/pdf/2311.02462.pdf)
* [State of reasoning in LLMs](https://medium.com/towards-data-science/solving-reasoning-problems-with-llms-in-2023-6643bdfd606d) (some of the latest techniques in prompting)
* [Building Full Stack Apps with AI Agents](https://medium.com/databutton/building-next-gen-apps-with-ai-agents-f18551c71218)
* [Compound AI systems](https://bair.berkeley.edu/blog/2024/02/18/compound-ai-systems/) (Berkeley)


Safety solutions


* Tools for controlling LM outputs: [Guardrails](https://www.guardrailsai.com/), [LMQL](https://lmql.ai/), and [SGLang](https://arxiv.org/pdf/2312.07104.pdf)
* Inference strategies to generate better outputs using calls to models and tools: [chain\-of\-thought](https://arxiv.org/pdf/2201.11903.pdf), [self\-consistency](https://arxiv.org/pdf/2203.11171.pdf), [WikiChat](https://arxiv.org/pdf/2305.14292.pdf), [RAG](https://arxiv.org/pdf/2005.11401.pdf)
* [Red teaming AI: the devil is in the details](https://www.techpolicy.press/red-teaming-ai-the-devil-is-in-the-details/)
* [Validating qualitative analysis done by GenAI](https://mandenews.blogspot.com/2023/08/evaluating-thematic-coding-and-text.html)
* [Retrieval\-augmented Generation Realized: Strategic \& Technical Insights for Industrial Applications](https://www.appliedai.de/assets/files/retrieval-augmented-generation-realized/AppliedAI_White_Paper_Retrieval-augmented-Generation-Realized_FINAL_20240618.pdf)


Please see other "scoping" articles for social impact organizations, just like seen at the bottom of the page here: <https://datakind.github.io/scoping.html>
